{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = plt.figure(figsize=(20,20))\n",
    "# for i in range(6):\n",
    "#     ax = fig.add_subplot(1,6, i+1, xticks=[], yticks=[])\n",
    "#     ax.imshow(X_train[i], cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resacle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical integer labels using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print(\"one-hot labels:\")\n",
    "# print(y_train[:10])\n",
    "# how split \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-36-836525e13967>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-836525e13967>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    define model architecture\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy' , optimizer='rmsprop' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 7s 141us/step - loss: 0.2798 - acc: 0.9152 - val_loss: 0.1393 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13933, saving model to mnist.model.best.hdf5\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 7s 152us/step - loss: 0.1205 - acc: 0.9625 - val_loss: 0.1167 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13933 to 0.11666, saving model to mnist.model.best.hdf5\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 7s 149us/step - loss: 0.0890 - acc: 0.9735 - val_loss: 0.0902 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11666 to 0.09021, saving model to mnist.model.best.hdf5\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.0712 - acc: 0.9785 - val_loss: 0.0847 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09021 to 0.08472, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.0587 - acc: 0.9823 - val_loss: 0.0911 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08472\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 7s 154us/step - loss: 0.0507 - acc: 0.9851 - val_loss: 0.0907 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08472\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.0444 - acc: 0.9867 - val_loss: 0.1047 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08472\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.0417 - acc: 0.9878 - val_loss: 0.0917 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08472\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.0359 - acc: 0.9891 - val_loss: 0.1084 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08472\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.0328 - acc: 0.9905 - val_loss: 0.1067 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08472\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.best.hdf5' , verbose =1, save_best_only = True)\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs = 10, validation_split=0.2, callbacks=[checkpointer], verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('mnist.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate the classification accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.8700\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "accuracy = 100 * score[1]\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
