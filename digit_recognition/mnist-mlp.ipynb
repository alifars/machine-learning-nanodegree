{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "for i in range(6):\n",
    "    ax = fig.add_subplot(1,6, i+1, xticks=[], yticks=[])\n",
    "    ax.imshow(X_train[i], cmap='gray')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resacle the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rescale [0,255] --> [0,1]\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode categorical integer labels using one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import np_utils\n",
    "\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "# print(\"one-hot labels:\")\n",
    "# print(y_train[:10])\n",
    "# how split \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape = X_train.shape[1:]))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy' , optimizer='rmsprop' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/10\n",
      "48000/48000 [==============================] - 7s 141us/step - loss: 0.2798 - acc: 0.9152 - val_loss: 0.1393 - val_acc: 0.9577\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.13933, saving model to mnist.model.best.hdf5\n",
      "Epoch 2/10\n",
      "48000/48000 [==============================] - 7s 152us/step - loss: 0.1205 - acc: 0.9625 - val_loss: 0.1167 - val_acc: 0.9663\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.13933 to 0.11666, saving model to mnist.model.best.hdf5\n",
      "Epoch 3/10\n",
      "48000/48000 [==============================] - 7s 149us/step - loss: 0.0890 - acc: 0.9735 - val_loss: 0.0902 - val_acc: 0.9752\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.11666 to 0.09021, saving model to mnist.model.best.hdf5\n",
      "Epoch 4/10\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.0712 - acc: 0.9785 - val_loss: 0.0847 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.09021 to 0.08472, saving model to mnist.model.best.hdf5\n",
      "Epoch 5/10\n",
      "48000/48000 [==============================] - 7s 148us/step - loss: 0.0587 - acc: 0.9823 - val_loss: 0.0911 - val_acc: 0.9779\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.08472\n",
      "Epoch 6/10\n",
      "48000/48000 [==============================] - 7s 154us/step - loss: 0.0507 - acc: 0.9851 - val_loss: 0.0907 - val_acc: 0.9764\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.08472\n",
      "Epoch 7/10\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.0444 - acc: 0.9867 - val_loss: 0.1047 - val_acc: 0.9765\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.08472\n",
      "Epoch 8/10\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.0417 - acc: 0.9878 - val_loss: 0.0917 - val_acc: 0.9807\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.08472\n",
      "Epoch 9/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.0359 - acc: 0.9891 - val_loss: 0.1084 - val_acc: 0.9793\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.08472\n",
      "Epoch 10/10\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.0328 - acc: 0.9905 - val_loss: 0.1067 - val_acc: 0.9792\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.08472\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='mnist.model.best.hdf5' , verbose =1, save_best_only = True)\n",
    "\n",
    "hist = model.fit(X_train, y_train, batch_size=128, epochs = 10, validation_split=0.2, callbacks=[checkpointer], verbose=1, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('mnist.model.best.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate the classification accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 97.8700\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose = 0)\n",
    "accuracy = 100 * score[1]\n",
    "print(\"Test accuracy: {:.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion:\n",
    "MLP gave us very good accuracy on MNIST dataset. Here we had clean images of digits all in same size, with digits always in same position. We should use CNN if we don't have such a clean and organized dataset.    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
